{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bed92fb",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f14306cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import operator\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from numpy import unique\n",
    "from numpy import reshape\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers import Conv1D, Conv2D, Dense, Dropout, BatchNormalization, Flatten, MaxPooling1D\n",
    "import keras\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c9e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from keras.layers import Conv1D, Conv2D, Dense, BatchNormalization, Flatten, MaxPooling1D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a9794",
   "metadata": {},
   "source": [
    "# Importing cleaned sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb7ea541",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"C:\\Users\\Sam\\Desktop\\CF\\Machine Learning\\Part 2\\2.2 Complex ML models and Keras part 1\\Dataset-Answers-Weather_Prediction_Pleasant_Weather-CLEANED.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c5defa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers=pd.read_csv(os.path.join(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca767b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathw=r\"C:\\Users\\Sam\\Desktop\\CF\\Machine Learning\\Part 2\\2.2 Complex ML models and Keras part 1\\Dataset-weather-prediction-dataset-processed-CLEANED.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "645fe87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather=pd.read_csv(os.path.join(pathw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "755d946e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ded2edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22950, 135)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c488d9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BASEL_cloud_cover', 'BASEL_humidity', 'BASEL_pressure',\n",
       "       'BASEL_global_radiation', 'BASEL_precipitation', 'BASEL_sunshine',\n",
       "       'BASEL_temp_mean', 'BASEL_temp_min', 'BASEL_temp_max',\n",
       "       'BELGRADE_cloud_cover',\n",
       "       ...\n",
       "       'STOCKHOLM_temp_max', 'VALENTIA_cloud_cover', 'VALENTIA_humidity',\n",
       "       'VALENTIA_pressure', 'VALENTIA_global_radiation',\n",
       "       'VALENTIA_precipitation', 'VALENTIA_sunshine', 'VALENTIA_temp_mean',\n",
       "       'VALENTIA_temp_min', 'VALENTIA_temp_max'],\n",
       "      dtype='object', length=135)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aa1fd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cloud_cover',\n",
       " 'humidity',\n",
       " 'pressure',\n",
       " 'global_radiation',\n",
       " 'precipitation',\n",
       " 'sunshine',\n",
       " 'temp_mean',\n",
       " 'temp_min',\n",
       " 'temp_max']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes=[col.replace(\"BASEL_\",\"\") for col in weather.columns[:9]]\n",
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b89dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=weather.values\n",
    "X=X.reshape(-1,1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "869de802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 7.    ,  0.85  ,  1.018 , ...,  6.5   ,  0.8   , 10.9   ]],\n",
       "\n",
       "       [[ 1.    ,  0.81  ,  1.0195, ...,  3.7   , -0.9   ,  7.9   ]],\n",
       "\n",
       "       [[ 4.    ,  0.67  ,  1.017 , ...,  2.4   , -0.4   ,  5.1   ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4.    ,  0.84  ,  1.0263, ...,  1.7   ,  0.7   ,  2.7   ]],\n",
       "\n",
       "       [[ 5.    ,  0.97  ,  1.0164, ...,  9.7   ,  5.    , 12.6   ]],\n",
       "\n",
       "       [[ 5.    ,  0.82  ,  1.0142, ..., 10.7   ,  7.9   , 13.5   ]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b91782e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=answers.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aac8b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7205099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a048cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344250"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e804d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18f3cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "877a5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bay_area(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs,\n",
    "              layers1, layers2, normalization, dropout, dropout_rate): \n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "    optimizerD= {'Adam':Adam(learning_rate=learning_rate), 'SGD':SGD(learning_rate=learning_rate),\n",
    "                 'RMSprop':RMSprop(learning_rate=learning_rate), 'Adadelta':Adadelta(learning_rate=learning_rate),\n",
    "                 'Adagrad':Adagrad(learning_rate=learning_rate), 'Adamax':Adamax(learning_rate=learning_rate),\n",
    "                 'Nadam':Nadam(learning_rate=learning_rate), 'Ftrl':Ftrl(learning_rate=learning_rate)}\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential', LeakyReLU,'relu']\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    kernel = round(kernel)\n",
    "    activation = activationL[round(activation)]\n",
    "    optimizer = optimizerD[optimizerL[round(optimizer)]]\n",
    "    batch_size = round(batch_size)\n",
    "    \n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    \n",
    "    def cnn_model():\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n",
    "        #model.add(Conv1D(32, kernel_size=1,activation='relu', input_shape=(timesteps, input_dim)))\n",
    "        \n",
    "        if normalization > 0.5:\n",
    "            model.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            model.add(Dense(neurons, activation=activation)) #(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            model.add(Dropout(dropout_rate, seed=123))\n",
    "        for i in range(layers2):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        #model.add(MaxPooling1D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(n_classes, activation='softmax')) #sigmoid softmax\n",
    "        #model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #categorical_crossentropy\n",
    "        return model\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=2, patience=20)\n",
    "    nn = KerasClassifier(build_fn=cnn_model, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55218cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from numpy import unique\n",
    "from numpy import reshape\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers import Conv1D, Conv2D, Dense, Dropout, BatchNormalization, Flatten, MaxPooling1D\n",
    "\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import LeakyReLU\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c51402cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "413a0b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  kernel   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 1/32\n",
      "230/230 - 2s - loss: 0.5176 - accuracy: 0.7814 - 2s/epoch - 10ms/step\n",
      "Epoch 2/32\n",
      "230/230 - 1s - loss: 0.4679 - accuracy: 0.7801 - 1s/epoch - 5ms/step\n",
      "Epoch 3/32\n",
      "230/230 - 1s - loss: 0.2782 - accuracy: 0.8677 - 1s/epoch - 5ms/step\n",
      "Epoch 4/32\n",
      "230/230 - 1s - loss: 0.2444 - accuracy: 0.8864 - 1s/epoch - 5ms/step\n",
      "Epoch 5/32\n",
      "230/230 - 1s - loss: 0.2287 - accuracy: 0.8932 - 1s/epoch - 5ms/step\n",
      "Epoch 6/32\n",
      "230/230 - 1s - loss: 0.2212 - accuracy: 0.8970 - 1s/epoch - 5ms/step\n",
      "Epoch 7/32\n",
      "230/230 - 1s - loss: 0.2115 - accuracy: 0.8994 - 1s/epoch - 5ms/step\n",
      "Epoch 8/32\n",
      "230/230 - 1s - loss: 0.2047 - accuracy: 0.9035 - 1s/epoch - 5ms/step\n",
      "Epoch 9/32\n",
      "230/230 - 1s - loss: 0.1975 - accuracy: 0.9057 - 1s/epoch - 5ms/step\n",
      "Epoch 10/32\n",
      "230/230 - 1s - loss: 0.1892 - accuracy: 0.9097 - 1s/epoch - 5ms/step\n",
      "Epoch 11/32\n",
      "230/230 - 1s - loss: 0.1839 - accuracy: 0.9132 - 1s/epoch - 5ms/step\n",
      "Epoch 12/32\n",
      "230/230 - 1s - loss: 0.1760 - accuracy: 0.9175 - 1s/epoch - 5ms/step\n",
      "Epoch 13/32\n",
      "230/230 - 1s - loss: 0.1709 - accuracy: 0.9209 - 1s/epoch - 5ms/step\n",
      "Epoch 14/32\n",
      "230/230 - 1s - loss: 0.1669 - accuracy: 0.9227 - 1s/epoch - 5ms/step\n",
      "Epoch 15/32\n",
      "230/230 - 1s - loss: 0.1628 - accuracy: 0.9246 - 1s/epoch - 5ms/step\n",
      "Epoch 16/32\n",
      "230/230 - 1s - loss: 0.1601 - accuracy: 0.9264 - 1s/epoch - 5ms/step\n",
      "Epoch 17/32\n",
      "230/230 - 1s - loss: 0.1587 - accuracy: 0.9275 - 1s/epoch - 5ms/step\n",
      "Epoch 18/32\n",
      "230/230 - 1s - loss: 0.1545 - accuracy: 0.9296 - 1s/epoch - 5ms/step\n",
      "Epoch 19/32\n",
      "230/230 - 1s - loss: 0.1528 - accuracy: 0.9309 - 1s/epoch - 5ms/step\n",
      "Epoch 20/32\n",
      "230/230 - 1s - loss: 0.1493 - accuracy: 0.9327 - 1s/epoch - 5ms/step\n",
      "Epoch 21/32\n",
      "230/230 - 1s - loss: 0.1509 - accuracy: 0.9316 - 1s/epoch - 5ms/step\n",
      "Epoch 22/32\n",
      "230/230 - 1s - loss: 0.1461 - accuracy: 0.9341 - 1s/epoch - 5ms/step\n",
      "Epoch 23/32\n",
      "230/230 - 1s - loss: 0.1445 - accuracy: 0.9352 - 1s/epoch - 5ms/step\n",
      "Epoch 24/32\n",
      "230/230 - 1s - loss: 0.1441 - accuracy: 0.9354 - 1s/epoch - 5ms/step\n",
      "Epoch 25/32\n",
      "230/230 - 1s - loss: 0.1438 - accuracy: 0.9358 - 1s/epoch - 5ms/step\n",
      "Epoch 26/32\n",
      "230/230 - 1s - loss: 0.1414 - accuracy: 0.9368 - 1s/epoch - 5ms/step\n",
      "Epoch 27/32\n",
      "230/230 - 1s - loss: 0.1400 - accuracy: 0.9379 - 1s/epoch - 5ms/step\n",
      "Epoch 28/32\n",
      "230/230 - 1s - loss: 0.1362 - accuracy: 0.9399 - 1s/epoch - 6ms/step\n",
      "Epoch 29/32\n",
      "230/230 - 1s - loss: 0.1370 - accuracy: 0.9394 - 1s/epoch - 5ms/step\n",
      "Epoch 30/32\n",
      "230/230 - 1s - loss: 0.1389 - accuracy: 0.9387 - 1s/epoch - 5ms/step\n",
      "Epoch 31/32\n",
      "230/230 - 1s - loss: 0.1345 - accuracy: 0.9399 - 1s/epoch - 5ms/step\n",
      "Epoch 32/32\n",
      "230/230 - 1s - loss: 0.1303 - accuracy: 0.9428 - 1s/epoch - 5ms/step\n",
      "1722/1722 [==============================] - 3s 1ms/step\n",
      "Epoch 1/32\n",
      "230/230 - 2s - loss: 0.7816 - accuracy: 0.7443 - 2s/epoch - 9ms/step\n",
      "Epoch 2/32\n",
      "230/230 - 1s - loss: 0.5230 - accuracy: 0.7754 - 1s/epoch - 5ms/step\n",
      "Epoch 3/32\n",
      "230/230 - 1s - loss: 0.2912 - accuracy: 0.8621 - 1s/epoch - 5ms/step\n",
      "Epoch 4/32\n",
      "230/230 - 1s - loss: 0.2491 - accuracy: 0.8847 - 1s/epoch - 5ms/step\n",
      "Epoch 5/32\n",
      "230/230 - 1s - loss: 0.2295 - accuracy: 0.8924 - 1s/epoch - 5ms/step\n",
      "Epoch 6/32\n",
      "230/230 - 1s - loss: 0.2193 - accuracy: 0.8984 - 1s/epoch - 5ms/step\n",
      "Epoch 7/32\n",
      "230/230 - 1s - loss: 0.2115 - accuracy: 0.9007 - 1s/epoch - 5ms/step\n",
      "Epoch 8/32\n",
      "230/230 - 1s - loss: 0.2023 - accuracy: 0.9047 - 1s/epoch - 5ms/step\n",
      "Epoch 9/32\n",
      "230/230 - 1s - loss: 0.1981 - accuracy: 0.9067 - 1s/epoch - 5ms/step\n",
      "Epoch 10/32\n",
      "230/230 - 1s - loss: 0.1862 - accuracy: 0.9123 - 1s/epoch - 5ms/step\n",
      "Epoch 11/32\n",
      "230/230 - 1s - loss: 0.1830 - accuracy: 0.9133 - 1s/epoch - 5ms/step\n",
      "Epoch 12/32\n",
      "230/230 - 1s - loss: 0.1742 - accuracy: 0.9188 - 1s/epoch - 5ms/step\n",
      "Epoch 13/32\n",
      "230/230 - 1s - loss: 0.1696 - accuracy: 0.9210 - 1s/epoch - 5ms/step\n",
      "Epoch 14/32\n",
      "230/230 - 1s - loss: 0.1645 - accuracy: 0.9239 - 1s/epoch - 5ms/step\n",
      "Epoch 15/32\n",
      "230/230 - 1s - loss: 0.1631 - accuracy: 0.9240 - 1s/epoch - 5ms/step\n",
      "Epoch 16/32\n",
      "230/230 - 1s - loss: 0.1585 - accuracy: 0.9272 - 1s/epoch - 5ms/step\n",
      "Epoch 17/32\n",
      "230/230 - 1s - loss: 0.1548 - accuracy: 0.9294 - 1s/epoch - 5ms/step\n",
      "Epoch 18/32\n",
      "230/230 - 1s - loss: 0.1536 - accuracy: 0.9300 - 1s/epoch - 5ms/step\n",
      "Epoch 19/32\n",
      "230/230 - 1s - loss: 0.1493 - accuracy: 0.9326 - 1s/epoch - 5ms/step\n",
      "Epoch 20/32\n",
      "230/230 - 1s - loss: 0.1487 - accuracy: 0.9328 - 1s/epoch - 5ms/step\n",
      "Epoch 21/32\n",
      "230/230 - 1s - loss: 0.1456 - accuracy: 0.9347 - 1s/epoch - 5ms/step\n",
      "Epoch 22/32\n",
      "230/230 - 1s - loss: 0.1438 - accuracy: 0.9345 - 1s/epoch - 5ms/step\n",
      "Epoch 23/32\n",
      "230/230 - 1s - loss: 0.1408 - accuracy: 0.9364 - 1s/epoch - 5ms/step\n",
      "Epoch 24/32\n",
      "230/230 - 1s - loss: 0.1392 - accuracy: 0.9379 - 1s/epoch - 5ms/step\n",
      "Epoch 25/32\n",
      "230/230 - 1s - loss: 0.1365 - accuracy: 0.9391 - 1s/epoch - 5ms/step\n",
      "Epoch 26/32\n",
      "230/230 - 1s - loss: 0.1370 - accuracy: 0.9391 - 1s/epoch - 5ms/step\n",
      "Epoch 27/32\n",
      "230/230 - 1s - loss: 0.1340 - accuracy: 0.9411 - 1s/epoch - 6ms/step\n",
      "Epoch 28/32\n",
      "230/230 - 1s - loss: 0.1320 - accuracy: 0.9414 - 1s/epoch - 5ms/step\n",
      "Epoch 29/32\n",
      "230/230 - 1s - loss: 0.1314 - accuracy: 0.9426 - 1s/epoch - 5ms/step\n",
      "Epoch 30/32\n",
      "230/230 - 1s - loss: 0.1299 - accuracy: 0.9425 - 1s/epoch - 5ms/step\n",
      "Epoch 31/32\n",
      "230/230 - 1s - loss: 0.1272 - accuracy: 0.9440 - 1s/epoch - 5ms/step\n",
      "Epoch 32/32\n",
      "230/230 - 1s - loss: 0.1262 - accuracy: 0.9451 - 1s/epoch - 5ms/step\n",
      "1722/1722 [==============================] - 2s 1ms/step\n",
      "Epoch 1/32\n",
      "230/230 - 2s - loss: 0.5199 - accuracy: 0.7854 - 2s/epoch - 9ms/step\n",
      "Epoch 2/32\n",
      "230/230 - 1s - loss: 0.5142 - accuracy: 0.7831 - 1s/epoch - 5ms/step\n",
      "Epoch 3/32\n",
      "230/230 - 1s - loss: 0.4485 - accuracy: 0.7905 - 1s/epoch - 5ms/step\n",
      "Epoch 4/32\n",
      "230/230 - 1s - loss: 0.2778 - accuracy: 0.8667 - 1s/epoch - 5ms/step\n",
      "Epoch 5/32\n",
      "230/230 - 1s - loss: 0.2469 - accuracy: 0.8838 - 1s/epoch - 5ms/step\n",
      "Epoch 6/32\n",
      "230/230 - 1s - loss: 0.2311 - accuracy: 0.8907 - 1s/epoch - 6ms/step\n",
      "Epoch 7/32\n",
      "230/230 - 1s - loss: 0.2224 - accuracy: 0.8948 - 1s/epoch - 5ms/step\n",
      "Epoch 8/32\n",
      "230/230 - 1s - loss: 0.2147 - accuracy: 0.8979 - 1s/epoch - 5ms/step\n",
      "Epoch 9/32\n",
      "230/230 - 1s - loss: 0.2053 - accuracy: 0.9003 - 1s/epoch - 5ms/step\n",
      "Epoch 10/32\n",
      "230/230 - 1s - loss: 0.1997 - accuracy: 0.9041 - 1s/epoch - 5ms/step\n",
      "Epoch 11/32\n",
      "230/230 - 1s - loss: 0.1897 - accuracy: 0.9097 - 1s/epoch - 5ms/step\n",
      "Epoch 12/32\n",
      "230/230 - 1s - loss: 0.1772 - accuracy: 0.9169 - 1s/epoch - 5ms/step\n",
      "Epoch 13/32\n",
      "230/230 - 1s - loss: 0.1690 - accuracy: 0.9224 - 1s/epoch - 5ms/step\n",
      "Epoch 14/32\n",
      "230/230 - 1s - loss: 0.1620 - accuracy: 0.9259 - 1s/epoch - 5ms/step\n",
      "Epoch 15/32\n",
      "230/230 - 1s - loss: 0.1618 - accuracy: 0.9263 - 1s/epoch - 5ms/step\n",
      "Epoch 16/32\n",
      "230/230 - 1s - loss: 0.1559 - accuracy: 0.9294 - 1s/epoch - 5ms/step\n",
      "Epoch 17/32\n",
      "230/230 - 1s - loss: 0.1536 - accuracy: 0.9309 - 1s/epoch - 5ms/step\n",
      "Epoch 18/32\n",
      "230/230 - 1s - loss: 0.1504 - accuracy: 0.9331 - 1s/epoch - 6ms/step\n",
      "Epoch 19/32\n",
      "230/230 - 1s - loss: 0.1483 - accuracy: 0.9338 - 1s/epoch - 6ms/step\n",
      "Epoch 20/32\n",
      "230/230 - 1s - loss: 0.1447 - accuracy: 0.9363 - 1s/epoch - 5ms/step\n",
      "Epoch 21/32\n",
      "230/230 - 1s - loss: 0.1432 - accuracy: 0.9363 - 1s/epoch - 5ms/step\n",
      "Epoch 22/32\n",
      "230/230 - 1s - loss: 0.1419 - accuracy: 0.9382 - 1s/epoch - 5ms/step\n",
      "Epoch 23/32\n",
      "230/230 - 1s - loss: 0.1389 - accuracy: 0.9394 - 1s/epoch - 5ms/step\n",
      "Epoch 24/32\n",
      "230/230 - 1s - loss: 0.1364 - accuracy: 0.9411 - 1s/epoch - 5ms/step\n",
      "Epoch 25/32\n",
      "230/230 - 1s - loss: 0.1354 - accuracy: 0.9415 - 1s/epoch - 5ms/step\n",
      "Epoch 26/32\n",
      "230/230 - 1s - loss: 0.1340 - accuracy: 0.9416 - 1s/epoch - 5ms/step\n",
      "Epoch 27/32\n",
      "230/230 - 1s - loss: 0.1337 - accuracy: 0.9425 - 1s/epoch - 5ms/step\n",
      "Epoch 28/32\n",
      "230/230 - 1s - loss: 0.1308 - accuracy: 0.9440 - 1s/epoch - 5ms/step\n",
      "Epoch 29/32\n",
      "230/230 - 1s - loss: 0.1295 - accuracy: 0.9444 - 1s/epoch - 5ms/step\n",
      "Epoch 30/32\n",
      "230/230 - 1s - loss: 0.1287 - accuracy: 0.9445 - 1s/epoch - 5ms/step\n",
      "Epoch 31/32\n",
      "230/230 - 1s - loss: 0.1275 - accuracy: 0.9453 - 1s/epoch - 5ms/step\n",
      "Epoch 32/32\n",
      "230/230 - 1s - loss: 0.1256 - accuracy: 0.9462 - 1s/epoch - 6ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1722/1722 [==============================] - 2s 1ms/step\n",
      "Epoch 1/32\n",
      "230/230 - 2s - loss: 0.4737 - accuracy: 0.7784 - 2s/epoch - 9ms/step\n",
      "Epoch 2/32\n",
      "230/230 - 1s - loss: 0.2908 - accuracy: 0.8567 - 1s/epoch - 5ms/step\n",
      "Epoch 3/32\n",
      "230/230 - 1s - loss: 0.2475 - accuracy: 0.8833 - 1s/epoch - 5ms/step\n",
      "Epoch 4/32\n",
      "230/230 - 1s - loss: 0.2308 - accuracy: 0.8906 - 1s/epoch - 5ms/step\n",
      "Epoch 5/32\n",
      "230/230 - 1s - loss: 0.2247 - accuracy: 0.8924 - 1s/epoch - 5ms/step\n",
      "Epoch 6/32\n",
      "230/230 - 1s - loss: 0.2162 - accuracy: 0.8971 - 1s/epoch - 5ms/step\n",
      "Epoch 7/32\n",
      "230/230 - 1s - loss: 0.2088 - accuracy: 0.9008 - 1s/epoch - 5ms/step\n",
      "Epoch 8/32\n",
      "230/230 - 1s - loss: 0.2151 - accuracy: 0.8993 - 1s/epoch - 5ms/step\n",
      "Epoch 9/32\n",
      "230/230 - 1s - loss: 0.1958 - accuracy: 0.9072 - 1s/epoch - 5ms/step\n",
      "Epoch 10/32\n",
      "230/230 - 1s - loss: 0.1882 - accuracy: 0.9113 - 1s/epoch - 6ms/step\n",
      "Epoch 11/32\n",
      "230/230 - 1s - loss: 0.1803 - accuracy: 0.9150 - 1s/epoch - 6ms/step\n",
      "Epoch 12/32\n",
      "230/230 - 1s - loss: 0.1736 - accuracy: 0.9182 - 1s/epoch - 6ms/step\n",
      "Epoch 13/32\n",
      "230/230 - 1s - loss: 0.1700 - accuracy: 0.9201 - 1s/epoch - 5ms/step\n",
      "Epoch 14/32\n",
      "230/230 - 1s - loss: 0.1629 - accuracy: 0.9240 - 1s/epoch - 5ms/step\n",
      "Epoch 15/32\n",
      "230/230 - 1s - loss: 0.1605 - accuracy: 0.9258 - 1s/epoch - 5ms/step\n",
      "Epoch 16/32\n",
      "230/230 - 1s - loss: 0.1551 - accuracy: 0.9292 - 1s/epoch - 5ms/step\n",
      "Epoch 17/32\n",
      "230/230 - 1s - loss: 0.1534 - accuracy: 0.9300 - 1s/epoch - 5ms/step\n",
      "Epoch 18/32\n",
      "230/230 - 1s - loss: 0.1509 - accuracy: 0.9315 - 1s/epoch - 5ms/step\n",
      "Epoch 19/32\n",
      "230/230 - 1s - loss: 0.1484 - accuracy: 0.9325 - 1s/epoch - 5ms/step\n",
      "Epoch 20/32\n",
      "230/230 - 1s - loss: 0.1460 - accuracy: 0.9342 - 1s/epoch - 5ms/step\n",
      "Epoch 21/32\n",
      "230/230 - 1s - loss: 0.1443 - accuracy: 0.9350 - 1s/epoch - 5ms/step\n",
      "Epoch 22/32\n",
      "230/230 - 1s - loss: 0.1414 - accuracy: 0.9366 - 1s/epoch - 5ms/step\n",
      "Epoch 23/32\n",
      "230/230 - 1s - loss: 0.1396 - accuracy: 0.9379 - 1s/epoch - 6ms/step\n",
      "Epoch 24/32\n",
      "230/230 - 1s - loss: 0.1388 - accuracy: 0.9381 - 1s/epoch - 5ms/step\n",
      "Epoch 25/32\n",
      "230/230 - 1s - loss: 0.1357 - accuracy: 0.9398 - 1s/epoch - 5ms/step\n",
      "Epoch 26/32\n",
      "230/230 - 1s - loss: 0.1343 - accuracy: 0.9410 - 1s/epoch - 5ms/step\n",
      "Epoch 27/32\n",
      "230/230 - 1s - loss: 0.1346 - accuracy: 0.9411 - 1s/epoch - 6ms/step\n",
      "Epoch 28/32\n",
      "230/230 - 1s - loss: 0.1333 - accuracy: 0.9416 - 1s/epoch - 5ms/step\n",
      "Epoch 29/32\n",
      "230/230 - 1s - loss: 0.1308 - accuracy: 0.9429 - 1s/epoch - 5ms/step\n",
      "Epoch 30/32\n",
      "230/230 - 1s - loss: 0.1308 - accuracy: 0.9432 - 1s/epoch - 5ms/step\n",
      "Epoch 31/32\n",
      "230/230 - 1s - loss: 0.1289 - accuracy: 0.9443 - 1s/epoch - 5ms/step\n",
      "Epoch 32/32\n",
      "230/230 - 1s - loss: 0.1279 - accuracy: 0.9453 - 1s/epoch - 5ms/step\n",
      "1722/1722 [==============================] - 2s 1ms/step\n",
      "Epoch 1/32\n",
      "230/230 - 2s - loss: 0.5028 - accuracy: 0.7769 - 2s/epoch - 10ms/step\n",
      "Epoch 2/32\n",
      "230/230 - 1s - loss: 0.3129 - accuracy: 0.8360 - 1s/epoch - 6ms/step\n",
      "Epoch 3/32\n",
      "230/230 - 1s - loss: 0.2601 - accuracy: 0.8777 - 1s/epoch - 6ms/step\n",
      "Epoch 4/32\n",
      "230/230 - 1s - loss: 0.2374 - accuracy: 0.8880 - 1s/epoch - 5ms/step\n",
      "Epoch 5/32\n",
      "230/230 - 1s - loss: 0.2278 - accuracy: 0.8909 - 1s/epoch - 5ms/step\n",
      "Epoch 6/32\n",
      "230/230 - 1s - loss: 0.2170 - accuracy: 0.8954 - 1s/epoch - 5ms/step\n",
      "Epoch 7/32\n",
      "230/230 - 1s - loss: 0.2126 - accuracy: 0.8973 - 1s/epoch - 5ms/step\n",
      "Epoch 8/32\n",
      "230/230 - 1s - loss: 0.2071 - accuracy: 0.9008 - 1s/epoch - 5ms/step\n",
      "Epoch 9/32\n",
      "230/230 - 1s - loss: 0.1938 - accuracy: 0.9086 - 1s/epoch - 5ms/step\n",
      "Epoch 10/32\n",
      "230/230 - 1s - loss: 0.1840 - accuracy: 0.9126 - 1s/epoch - 5ms/step\n",
      "Epoch 11/32\n",
      "230/230 - 1s - loss: 0.1771 - accuracy: 0.9173 - 1s/epoch - 5ms/step\n",
      "Epoch 12/32\n",
      "230/230 - 1s - loss: 0.1725 - accuracy: 0.9193 - 1s/epoch - 5ms/step\n",
      "Epoch 13/32\n",
      "230/230 - 1s - loss: 0.1658 - accuracy: 0.9235 - 1s/epoch - 5ms/step\n",
      "Epoch 14/32\n",
      "230/230 - 1s - loss: 0.1617 - accuracy: 0.9252 - 1s/epoch - 5ms/step\n",
      "Epoch 15/32\n",
      "230/230 - 1s - loss: 0.1595 - accuracy: 0.9266 - 1s/epoch - 6ms/step\n",
      "Epoch 16/32\n",
      "230/230 - 1s - loss: 0.1561 - accuracy: 0.9286 - 1s/epoch - 6ms/step\n",
      "Epoch 17/32\n",
      "230/230 - 1s - loss: 0.1517 - accuracy: 0.9321 - 1s/epoch - 5ms/step\n",
      "Epoch 18/32\n",
      "230/230 - 1s - loss: 0.1510 - accuracy: 0.9322 - 1s/epoch - 5ms/step\n",
      "Epoch 19/32\n",
      "230/230 - 1s - loss: 0.1458 - accuracy: 0.9355 - 1s/epoch - 5ms/step\n",
      "Epoch 20/32\n",
      "230/230 - 1s - loss: 0.1432 - accuracy: 0.9369 - 1s/epoch - 5ms/step\n",
      "Epoch 21/32\n",
      "230/230 - 1s - loss: 0.1430 - accuracy: 0.9372 - 1s/epoch - 5ms/step\n",
      "Epoch 22/32\n",
      "230/230 - 1s - loss: 0.1417 - accuracy: 0.9388 - 1s/epoch - 5ms/step\n",
      "Epoch 23/32\n",
      "230/230 - 1s - loss: 0.1396 - accuracy: 0.9393 - 1s/epoch - 5ms/step\n",
      "Epoch 24/32\n",
      "230/230 - 1s - loss: 0.1369 - accuracy: 0.9410 - 1s/epoch - 5ms/step\n",
      "Epoch 25/32\n",
      "230/230 - 1s - loss: 0.1357 - accuracy: 0.9419 - 1s/epoch - 5ms/step\n",
      "Epoch 26/32\n",
      "230/230 - 1s - loss: 0.1380 - accuracy: 0.9401 - 1s/epoch - 5ms/step\n",
      "Epoch 27/32\n",
      "230/230 - 1s - loss: 0.1353 - accuracy: 0.9418 - 1s/epoch - 5ms/step\n",
      "Epoch 28/32\n",
      "230/230 - 1s - loss: 0.1315 - accuracy: 0.9439 - 1s/epoch - 5ms/step\n",
      "Epoch 29/32\n",
      "230/230 - 1s - loss: 0.1306 - accuracy: 0.9443 - 1s/epoch - 6ms/step\n",
      "Epoch 30/32\n",
      "230/230 - 1s - loss: 0.1280 - accuracy: 0.9461 - 1s/epoch - 6ms/step\n",
      "Epoch 31/32\n",
      "230/230 - 1s - loss: 0.1328 - accuracy: 0.9426 - 1s/epoch - 5ms/step\n",
      "Epoch 32/32\n",
      "230/230 - 1s - loss: 0.1259 - accuracy: 0.9471 - 1s/epoch - 5ms/step\n",
      "1722/1722 [==============================] - 2s 1ms/step\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9399   \u001b[0m | \u001b[0m3.371    \u001b[0m | \u001b[0m960.6    \u001b[0m | \u001b[0m0.732    \u001b[0m | \u001b[0m0.1796   \u001b[0m | \u001b[0m32.48    \u001b[0m | \u001b[0m1.312    \u001b[0m | \u001b[0m1.116    \u001b[0m | \u001b[0m2.732    \u001b[0m | \u001b[0m0.6051   \u001b[0m | \u001b[0m73.73    \u001b[0m | \u001b[0m0.02058  \u001b[0m | \u001b[0m6.789    \u001b[0m |\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 164, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9736\\2637969093.py\", line 23, in cnn_model\n    model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1973, in _create_c_op\n    raise ValueError(e.message)\nValueError: Exception encountered when calling layer \"conv1d_5\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d_5/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_5/Conv1D/ExpandDims, conv1d_5/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,9], [1,2,9,23].\n\nCall arguments received by layer \"conv1d_5\" (type Conv1D):\n  • inputs=tf.Tensor(shape=(None, 1, 9), dtype=float32)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 164, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9736\\2637969093.py\", line 23, in cnn_model\n    model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1973, in _create_c_op\n    raise ValueError(e.message)\nValueError: Exception encountered when calling layer \"conv1d_6\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d_6/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_6/Conv1D/ExpandDims, conv1d_6/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,9], [1,2,9,23].\n\nCall arguments received by layer \"conv1d_6\" (type Conv1D):\n  • inputs=tf.Tensor(shape=(None, 1, 9), dtype=float32)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 164, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9736\\2637969093.py\", line 23, in cnn_model\n    model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1973, in _create_c_op\n    raise ValueError(e.message)\nValueError: Exception encountered when calling layer \"conv1d_7\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d_7/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_7/Conv1D/ExpandDims, conv1d_7/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,9], [1,2,9,23].\n\nCall arguments received by layer \"conv1d_7\" (type Conv1D):\n  • inputs=tf.Tensor(shape=(None, 1, 9), dtype=float32)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 164, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9736\\2637969093.py\", line 23, in cnn_model\n    model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1973, in _create_c_op\n    raise ValueError(e.message)\nValueError: Exception encountered when calling layer \"conv1d_8\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d_8/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_8/Conv1D/ExpandDims, conv1d_8/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,9], [1,2,9,23].\n\nCall arguments received by layer \"conv1d_8\" (type Conv1D):\n  • inputs=tf.Tensor(shape=(None, 1, 9), dtype=float32)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 164, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9736\\2637969093.py\", line 23, in cnn_model\n    model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1973, in _create_c_op\n    raise ValueError(e.message)\nValueError: Exception encountered when calling layer \"conv1d_9\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d_9/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_9/Conv1D/ExpandDims, conv1d_9/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,9], [1,2,9,23].\n\nCall arguments received by layer \"conv1d_9\" (type Conv1D):\n  • inputs=tf.Tensor(shape=(None, 1, 9), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Run Bayesian Optimization\u001b[39;00m\n\u001b[0;32m     17\u001b[0m nn_opt \u001b[38;5;241m=\u001b[39m BayesianOptimization(bay_area, params, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m nn_opt\u001b[38;5;241m.\u001b[39mmaximize(init_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;66;03m#25\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSearch took \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:310\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    308\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[0;32m    309\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\n\u001b[0;32m    316\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:208\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(params)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mprobe(params)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\bayes_opt\\target_space.py:236\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    234\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_as_array(params)\n\u001b[0;32m    235\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys, x))\n\u001b[1;32m--> 236\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[1;32mIn[22], line 43\u001b[0m, in \u001b[0;36mbay_area\u001b[1;34m(neurons, activation, kernel, optimizer, learning_rate, batch_size, epochs, layers1, layers2, normalization, dropout, dropout_rate)\u001b[0m\n\u001b[0;32m     41\u001b[0m nn \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39mcnn_model, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     42\u001b[0m kfold \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m score \u001b[38;5;241m=\u001b[39m cross_val_score(nn, X_train, y_train, scoring\u001b[38;5;241m=\u001b[39mscore_acc, cv\u001b[38;5;241m=\u001b[39mkfold, fit_params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m'\u001b[39m:[es]})\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    720\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    721\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    722\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    723\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    724\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[0;32m    725\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    726\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    727\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    728\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[0;32m    729\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    730\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[0;32m    731\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    732\u001b[0m )\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:450\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    431\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    432\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    448\u001b[0m )\n\u001b[1;32m--> 450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m     )\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 164, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9736\\2637969093.py\", line 23, in cnn_model\n    model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1973, in _create_c_op\n    raise ValueError(e.message)\nValueError: Exception encountered when calling layer \"conv1d_5\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d_5/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_5/Conv1D/ExpandDims, conv1d_5/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,9], [1,2,9,23].\n\nCall arguments received by layer \"conv1d_5\" (type Conv1D):\n  • inputs=tf.Tensor(shape=(None, 1, 9), dtype=float32)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 164, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9736\\2637969093.py\", line 23, in cnn_model\n    model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1973, in _create_c_op\n    raise ValueError(e.message)\nValueError: Exception encountered when calling layer \"conv1d_6\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d_6/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_6/Conv1D/ExpandDims, conv1d_6/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,9], [1,2,9,23].\n\nCall arguments received by layer \"conv1d_6\" (type Conv1D):\n  • inputs=tf.Tensor(shape=(None, 1, 9), dtype=float32)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 164, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9736\\2637969093.py\", line 23, in cnn_model\n    model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1973, in _create_c_op\n    raise ValueError(e.message)\nValueError: Exception encountered when calling layer \"conv1d_7\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d_7/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_7/Conv1D/ExpandDims, conv1d_7/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,9], [1,2,9,23].\n\nCall arguments received by layer \"conv1d_7\" (type Conv1D):\n  • inputs=tf.Tensor(shape=(None, 1, 9), dtype=float32)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 164, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9736\\2637969093.py\", line 23, in cnn_model\n    model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1973, in _create_c_op\n    raise ValueError(e.message)\nValueError: Exception encountered when calling layer \"conv1d_8\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d_8/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_8/Conv1D/ExpandDims, conv1d_8/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,9], [1,2,9,23].\n\nCall arguments received by layer \"conv1d_8\" (type Conv1D):\n  • inputs=tf.Tensor(shape=(None, 1, 9), dtype=float32)\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 164, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_9736\\2637969093.py\", line 23, in cnn_model\n    model.add(Conv1D(neurons, kernel_size=kernel,activation=activation, input_shape=(timesteps, input_dim)))\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\Sam\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1973, in _create_c_op\n    raise ValueError(e.message)\nValueError: Exception encountered when calling layer \"conv1d_9\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d_9/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_9/Conv1D/ExpandDims, conv1d_9/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,9], [1,2,9,23].\n\nCall arguments received by layer \"conv1d_9\" (type Conv1D):\n  • inputs=tf.Tensor(shape=(None, 1, 9), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "params ={\n",
    "    'neurons': (10, 100),\n",
    "    'kernel': (1, 3),\n",
    "    'activation':(0, 9), #9\n",
    "    'optimizer':(0,7), #7\n",
    "    'learning_rate':(0.01, 1),\n",
    "    'batch_size': (200, 1000), #(10, 50), #\n",
    "    'epochs':(20, 100),\n",
    "    'layers1':(1,3),\n",
    "    'layers2':(1,3),\n",
    "    'normalization':(0,1),\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0,0.3)\n",
    "}\n",
    "# Run Bayesian Optimization\n",
    "nn_opt = BayesianOptimization(bay_area, params, random_state=42)\n",
    "nn_opt.maximize(init_points=15, n_iter=4) #25\n",
    "print('Search took %s minutes' % ((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07e5d6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softsign',\n",
       " 'batch_size': 961,\n",
       " 'dropout': 0.7319939418114051,\n",
       " 'dropout_rate': 0.17959754525911098,\n",
       " 'epochs': 32,\n",
       " 'kernel': 1.3119890406724053,\n",
       " 'layers1': 1,\n",
       " 'layers2': 3,\n",
       " 'learning_rate': 0.6051038616257767,\n",
       " 'neurons': 74,\n",
       " 'normalization': 0.020584494295802447,\n",
       " 'optimizer': <keras.optimizers.legacy.ftrl.Ftrl at 0x223af4e76d0>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum = nn_opt.max['params']\n",
    "learning_rate = optimum['learning_rate']\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "               'elu', 'exponential', LeakyReLU,'relu']\n",
    "optimum['activation'] = activationL[round(optimum['activation'])]\n",
    "optimum['batch_size'] = round(optimum['batch_size'])\n",
    "optimum['epochs'] = round(optimum['epochs'])\n",
    "optimum['layers1'] = round(optimum['layers1'])\n",
    "optimum['layers2'] = round(optimum['layers2'])\n",
    "optimum['neurons'] = round(optimum['neurons'])\n",
    "optimizerL = ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','Adam']\n",
    "optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
    "             'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
    "             'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
    "             'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
    "optimum['optimizer'] = optimizerD[optimizerL[round(optimum['optimizer'])]]\n",
    "optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d271e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 32\n",
    "batch_size = 961\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 15\n",
    "layers1 = 1\n",
    "layers2 = 3\n",
    "activation = 'softsign'\n",
    "kernel = 1\n",
    "neurons = 74\n",
    "normalization = 0.020584494295802447\n",
    "dropout = 0.7319939418114051\n",
    "dropout_rate = 0.17959754525911098\n",
    "optimizer = 'Adadelta'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(neurons, kernel_size=kernel, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "if normalization > 0.5:\n",
    "    model.add(BatchNormalization())\n",
    "for i in range(layers1):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "if dropout > 0.5:\n",
    "    model.add(Dropout(dropout_rate, seed=123))\n",
    "for i in range(layers2):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_classes, activation='softmax')) #softmax sigmoid\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) #binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfc90bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "287/287 - 4s - loss: 2.4796 - accuracy: 0.4593 - 4s/epoch - 13ms/step\n",
      "Epoch 2/32\n",
      "287/287 - 2s - loss: 2.3818 - accuracy: 0.5778 - 2s/epoch - 7ms/step\n",
      "Epoch 3/32\n",
      "287/287 - 2s - loss: 2.2702 - accuracy: 0.6499 - 2s/epoch - 7ms/step\n",
      "Epoch 4/32\n",
      "287/287 - 2s - loss: 2.1463 - accuracy: 0.6847 - 2s/epoch - 8ms/step\n",
      "Epoch 5/32\n",
      "287/287 - 2s - loss: 2.0104 - accuracy: 0.7028 - 2s/epoch - 8ms/step\n",
      "Epoch 6/32\n",
      "287/287 - 2s - loss: 1.8648 - accuracy: 0.7160 - 2s/epoch - 7ms/step\n",
      "Epoch 7/32\n",
      "287/287 - 2s - loss: 1.7131 - accuracy: 0.7275 - 2s/epoch - 7ms/step\n",
      "Epoch 8/32\n",
      "287/287 - 2s - loss: 1.5598 - accuracy: 0.7370 - 2s/epoch - 7ms/step\n",
      "Epoch 9/32\n",
      "287/287 - 2s - loss: 1.4104 - accuracy: 0.7466 - 2s/epoch - 7ms/step\n",
      "Epoch 10/32\n",
      "287/287 - 2s - loss: 1.2693 - accuracy: 0.7561 - 2s/epoch - 7ms/step\n",
      "Epoch 11/32\n",
      "287/287 - 2s - loss: 1.1409 - accuracy: 0.7647 - 2s/epoch - 7ms/step\n",
      "Epoch 12/32\n",
      "287/287 - 2s - loss: 1.0275 - accuracy: 0.7723 - 2s/epoch - 7ms/step\n",
      "Epoch 13/32\n",
      "287/287 - 2s - loss: 0.9291 - accuracy: 0.7779 - 2s/epoch - 7ms/step\n",
      "Epoch 14/32\n",
      "287/287 - 2s - loss: 0.8461 - accuracy: 0.7817 - 2s/epoch - 7ms/step\n",
      "Epoch 15/32\n",
      "287/287 - 2s - loss: 0.7762 - accuracy: 0.7837 - 2s/epoch - 7ms/step\n",
      "Epoch 16/32\n",
      "287/287 - 2s - loss: 0.7175 - accuracy: 0.7848 - 2s/epoch - 7ms/step\n",
      "Epoch 17/32\n",
      "287/287 - 2s - loss: 0.6678 - accuracy: 0.7852 - 2s/epoch - 7ms/step\n",
      "Epoch 18/32\n",
      "287/287 - 2s - loss: 0.6250 - accuracy: 0.7854 - 2s/epoch - 7ms/step\n",
      "Epoch 19/32\n",
      "287/287 - 2s - loss: 0.5882 - accuracy: 0.7855 - 2s/epoch - 7ms/step\n",
      "Epoch 20/32\n",
      "287/287 - 2s - loss: 0.5552 - accuracy: 0.7855 - 2s/epoch - 8ms/step\n",
      "Epoch 21/32\n",
      "287/287 - 2s - loss: 0.5262 - accuracy: 0.7860 - 2s/epoch - 8ms/step\n",
      "Epoch 22/32\n",
      "287/287 - 2s - loss: 0.4998 - accuracy: 0.7886 - 2s/epoch - 7ms/step\n",
      "Epoch 23/32\n",
      "287/287 - 2s - loss: 0.4760 - accuracy: 0.7958 - 2s/epoch - 7ms/step\n",
      "Epoch 24/32\n",
      "287/287 - 2s - loss: 0.4543 - accuracy: 0.8084 - 2s/epoch - 8ms/step\n",
      "Epoch 25/32\n",
      "287/287 - 2s - loss: 0.4346 - accuracy: 0.8246 - 2s/epoch - 7ms/step\n",
      "Epoch 26/32\n",
      "287/287 - 2s - loss: 0.4171 - accuracy: 0.8399 - 2s/epoch - 7ms/step\n",
      "Epoch 27/32\n",
      "287/287 - 2s - loss: 0.4011 - accuracy: 0.8530 - 2s/epoch - 7ms/step\n",
      "Epoch 28/32\n",
      "287/287 - 2s - loss: 0.3867 - accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
      "Epoch 29/32\n",
      "287/287 - 2s - loss: 0.3740 - accuracy: 0.8698 - 2s/epoch - 7ms/step\n",
      "Epoch 30/32\n",
      "287/287 - 2s - loss: 0.3626 - accuracy: 0.8753 - 2s/epoch - 7ms/step\n",
      "Epoch 31/32\n",
      "287/287 - 2s - loss: 0.3525 - accuracy: 0.8791 - 2s/epoch - 7ms/step\n",
      "Epoch 32/32\n",
      "287/287 - 2s - loss: 0.3434 - accuracy: 0.8821 - 2s/epoch - 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x223ac583a10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20139147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying 100 epochs and 9 classes to see the difference\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 961\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 9\n",
    "layers1 = 1\n",
    "layers2 = 3\n",
    "activation = 'softsign'\n",
    "kernel = 1\n",
    "neurons = 74\n",
    "normalization = 0.020584494295802447\n",
    "dropout = 0.7319939418114051\n",
    "dropout_rate = 0.17959754525911098\n",
    "optimizer = 'Adadelta'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(neurons, kernel_size=kernel, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "if normalization > 0.5:\n",
    "    model.add(BatchNormalization())\n",
    "for i in range(layers1):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "if dropout > 0.5:\n",
    "    model.add(Dropout(dropout_rate, seed=123))\n",
    "for i in range(layers2):\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d545ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "287/287 - 3s - loss: 2.2311 - accuracy: 0.1693 - 3s/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "287/287 - 2s - loss: 2.1315 - accuracy: 0.2578 - 2s/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "287/287 - 2s - loss: 2.0153 - accuracy: 0.3706 - 2s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "287/287 - 2s - loss: 1.8822 - accuracy: 0.5741 - 2s/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "287/287 - 2s - loss: 1.7338 - accuracy: 0.7527 - 2s/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "287/287 - 2s - loss: 1.5707 - accuracy: 0.7970 - 2s/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "287/287 - 2s - loss: 1.4000 - accuracy: 0.7838 - 2s/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "287/287 - 2s - loss: 1.2313 - accuracy: 0.7824 - 2s/epoch - 6ms/step\n",
      "Epoch 9/100\n",
      "287/287 - 2s - loss: 1.0776 - accuracy: 0.7838 - 2s/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "287/287 - 2s - loss: 0.9468 - accuracy: 0.7846 - 2s/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "287/287 - 2s - loss: 0.8410 - accuracy: 0.7850 - 2s/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "287/287 - 2s - loss: 0.7579 - accuracy: 0.7852 - 2s/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "287/287 - 2s - loss: 0.6918 - accuracy: 0.7855 - 2s/epoch - 8ms/step\n",
      "Epoch 14/100\n",
      "287/287 - 2s - loss: 0.6374 - accuracy: 0.7863 - 2s/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "287/287 - 2s - loss: 0.5911 - accuracy: 0.7899 - 2s/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "287/287 - 2s - loss: 0.5507 - accuracy: 0.7984 - 2s/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "287/287 - 2s - loss: 0.5155 - accuracy: 0.8106 - 2s/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "287/287 - 2s - loss: 0.4847 - accuracy: 0.8237 - 2s/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "287/287 - 2s - loss: 0.4579 - accuracy: 0.8365 - 2s/epoch - 7ms/step\n",
      "Epoch 20/100\n",
      "287/287 - 2s - loss: 0.4348 - accuracy: 0.8472 - 2s/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "287/287 - 2s - loss: 0.4148 - accuracy: 0.8551 - 2s/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "287/287 - 3s - loss: 0.3971 - accuracy: 0.8617 - 3s/epoch - 10ms/step\n",
      "Epoch 23/100\n",
      "287/287 - 3s - loss: 0.3819 - accuracy: 0.8673 - 3s/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "287/287 - 2s - loss: 0.3686 - accuracy: 0.8712 - 2s/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "287/287 - 2s - loss: 0.3570 - accuracy: 0.8738 - 2s/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "287/287 - 2s - loss: 0.3471 - accuracy: 0.8760 - 2s/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "287/287 - 2s - loss: 0.3384 - accuracy: 0.8782 - 2s/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "287/287 - 2s - loss: 0.3303 - accuracy: 0.8797 - 2s/epoch - 7ms/step\n",
      "Epoch 29/100\n",
      "287/287 - 2s - loss: 0.3239 - accuracy: 0.8809 - 2s/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "287/287 - 2s - loss: 0.3178 - accuracy: 0.8816 - 2s/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "287/287 - 2s - loss: 0.3127 - accuracy: 0.8828 - 2s/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "287/287 - 2s - loss: 0.3077 - accuracy: 0.8831 - 2s/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "287/287 - 2s - loss: 0.3036 - accuracy: 0.8840 - 2s/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "287/287 - 2s - loss: 0.2996 - accuracy: 0.8849 - 2s/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "287/287 - 2s - loss: 0.2961 - accuracy: 0.8852 - 2s/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "287/287 - 2s - loss: 0.2929 - accuracy: 0.8855 - 2s/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "287/287 - 2s - loss: 0.2900 - accuracy: 0.8858 - 2s/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "287/287 - 2s - loss: 0.2873 - accuracy: 0.8861 - 2s/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "287/287 - 2s - loss: 0.2845 - accuracy: 0.8868 - 2s/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "287/287 - 2s - loss: 0.2824 - accuracy: 0.8871 - 2s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "287/287 - 2s - loss: 0.2800 - accuracy: 0.8878 - 2s/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "287/287 - 2s - loss: 0.2781 - accuracy: 0.8879 - 2s/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "287/287 - 2s - loss: 0.2764 - accuracy: 0.8880 - 2s/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "287/287 - 2s - loss: 0.2740 - accuracy: 0.8888 - 2s/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "287/287 - 2s - loss: 0.2724 - accuracy: 0.8882 - 2s/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "287/287 - 2s - loss: 0.2709 - accuracy: 0.8895 - 2s/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "287/287 - 2s - loss: 0.2694 - accuracy: 0.8895 - 2s/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "287/287 - 2s - loss: 0.2678 - accuracy: 0.8894 - 2s/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "287/287 - 2s - loss: 0.2663 - accuracy: 0.8904 - 2s/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "287/287 - 2s - loss: 0.2650 - accuracy: 0.8904 - 2s/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "287/287 - 2s - loss: 0.2636 - accuracy: 0.8908 - 2s/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "287/287 - 2s - loss: 0.2623 - accuracy: 0.8907 - 2s/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "287/287 - 2s - loss: 0.2611 - accuracy: 0.8911 - 2s/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "287/287 - 2s - loss: 0.2602 - accuracy: 0.8912 - 2s/epoch - 8ms/step\n",
      "Epoch 55/100\n",
      "287/287 - 2s - loss: 0.2588 - accuracy: 0.8914 - 2s/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "287/287 - 2s - loss: 0.2579 - accuracy: 0.8918 - 2s/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "287/287 - 2s - loss: 0.2567 - accuracy: 0.8918 - 2s/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "287/287 - 2s - loss: 0.2557 - accuracy: 0.8926 - 2s/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "287/287 - 2s - loss: 0.2545 - accuracy: 0.8926 - 2s/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "287/287 - 2s - loss: 0.2537 - accuracy: 0.8927 - 2s/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "287/287 - 2s - loss: 0.2528 - accuracy: 0.8929 - 2s/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "287/287 - 2s - loss: 0.2517 - accuracy: 0.8930 - 2s/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "287/287 - 2s - loss: 0.2512 - accuracy: 0.8932 - 2s/epoch - 7ms/step\n",
      "Epoch 64/100\n",
      "287/287 - 2s - loss: 0.2500 - accuracy: 0.8938 - 2s/epoch - 7ms/step\n",
      "Epoch 65/100\n",
      "287/287 - 2s - loss: 0.2494 - accuracy: 0.8939 - 2s/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "287/287 - 2s - loss: 0.2482 - accuracy: 0.8944 - 2s/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "287/287 - 2s - loss: 0.2479 - accuracy: 0.8937 - 2s/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "287/287 - 2s - loss: 0.2470 - accuracy: 0.8945 - 2s/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "287/287 - 2s - loss: 0.2465 - accuracy: 0.8948 - 2s/epoch - 7ms/step\n",
      "Epoch 70/100\n",
      "287/287 - 2s - loss: 0.2455 - accuracy: 0.8948 - 2s/epoch - 7ms/step\n",
      "Epoch 71/100\n",
      "287/287 - 2s - loss: 0.2446 - accuracy: 0.8952 - 2s/epoch - 7ms/step\n",
      "Epoch 72/100\n",
      "287/287 - 2s - loss: 0.2440 - accuracy: 0.8954 - 2s/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "287/287 - 2s - loss: 0.2435 - accuracy: 0.8951 - 2s/epoch - 7ms/step\n",
      "Epoch 74/100\n",
      "287/287 - 2s - loss: 0.2426 - accuracy: 0.8952 - 2s/epoch - 7ms/step\n",
      "Epoch 75/100\n",
      "287/287 - 2s - loss: 0.2419 - accuracy: 0.8955 - 2s/epoch - 7ms/step\n",
      "Epoch 76/100\n",
      "287/287 - 2s - loss: 0.2412 - accuracy: 0.8963 - 2s/epoch - 7ms/step\n",
      "Epoch 77/100\n",
      "287/287 - 2s - loss: 0.2403 - accuracy: 0.8963 - 2s/epoch - 7ms/step\n",
      "Epoch 78/100\n",
      "287/287 - 2s - loss: 0.2401 - accuracy: 0.8960 - 2s/epoch - 7ms/step\n",
      "Epoch 79/100\n",
      "287/287 - 2s - loss: 0.2394 - accuracy: 0.8965 - 2s/epoch - 7ms/step\n",
      "Epoch 80/100\n",
      "287/287 - 2s - loss: 0.2388 - accuracy: 0.8965 - 2s/epoch - 7ms/step\n",
      "Epoch 81/100\n",
      "287/287 - 2s - loss: 0.2380 - accuracy: 0.8972 - 2s/epoch - 7ms/step\n",
      "Epoch 82/100\n",
      "287/287 - 2s - loss: 0.2376 - accuracy: 0.8970 - 2s/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "287/287 - 2s - loss: 0.2372 - accuracy: 0.8968 - 2s/epoch - 7ms/step\n",
      "Epoch 84/100\n",
      "287/287 - 2s - loss: 0.2366 - accuracy: 0.8968 - 2s/epoch - 7ms/step\n",
      "Epoch 85/100\n",
      "287/287 - 2s - loss: 0.2360 - accuracy: 0.8973 - 2s/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "287/287 - 2s - loss: 0.2353 - accuracy: 0.8974 - 2s/epoch - 8ms/step\n",
      "Epoch 87/100\n",
      "287/287 - 2s - loss: 0.2347 - accuracy: 0.8975 - 2s/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "287/287 - 2s - loss: 0.2342 - accuracy: 0.8978 - 2s/epoch - 8ms/step\n",
      "Epoch 89/100\n",
      "287/287 - 2s - loss: 0.2333 - accuracy: 0.8981 - 2s/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "287/287 - 2s - loss: 0.2328 - accuracy: 0.8983 - 2s/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "287/287 - 2s - loss: 0.2327 - accuracy: 0.8981 - 2s/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "287/287 - 2s - loss: 0.2320 - accuracy: 0.8981 - 2s/epoch - 9ms/step\n",
      "Epoch 93/100\n",
      "287/287 - 2s - loss: 0.2315 - accuracy: 0.8987 - 2s/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "287/287 - 2s - loss: 0.2313 - accuracy: 0.8989 - 2s/epoch - 8ms/step\n",
      "Epoch 95/100\n",
      "287/287 - 2s - loss: 0.2303 - accuracy: 0.8991 - 2s/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "287/287 - 2s - loss: 0.2301 - accuracy: 0.8991 - 2s/epoch - 7ms/step\n",
      "Epoch 97/100\n",
      "287/287 - 2s - loss: 0.2293 - accuracy: 0.8994 - 2s/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "287/287 - 2s - loss: 0.2292 - accuracy: 0.8994 - 2s/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "287/287 - 2s - loss: 0.2284 - accuracy: 0.8999 - 2s/epoch - 7ms/step\n",
      "Epoch 100/100\n",
      "287/287 - 2s - loss: 0.2282 - accuracy: 0.9000 - 2s/epoch - 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x223a4e0b910>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98015930",
   "metadata": {},
   "source": [
    "## 90% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c724327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
